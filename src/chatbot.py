def chat_with_llm(query: str, context: list[str]) -> str:
    """Generate a natural language answer using an LLM
    with retrieved context (RAG).

    Args:
        query (str): User question.
        context (list[str]): Relevant retrieved chunks.
    Returns:
        str: Answer generated by the LLM.
    """
    pass
